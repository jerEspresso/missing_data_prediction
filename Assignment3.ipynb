{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3xQa6VlNAOe"
   },
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "0mG3n0qRNTSA",
    "outputId": "cb0eadbd-b8a8-41b1-e3b4-7f44b47a8804"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load MovieLens 100K dataset into a dataframe of pandas\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('ml-100k/u.data', sep='\\t', names=names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hFJT0QWudp1P"
   },
   "outputs": [],
   "source": [
    "# Select 500 most active users and 500 most active items from the dataset\n",
    "n_most_active_users = 500\n",
    "n_most_active_items = 500\n",
    "\n",
    "user_ids = df.groupby('user_id').count().sort_values(by='rating', ascending=False).head(n_most_active_users).index\n",
    "item_ids = df.groupby('item_id').count().sort_values(by='rating', ascending=False).head(n_most_active_items).index\n",
    "df = df[(df['user_id'].isin(user_ids)) & (df['item_id'].isin(item_ids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "r012fu0jJkJc"
   },
   "outputs": [],
   "source": [
    "# Map new internal ID for items\n",
    "i_ids = df['item_id'].unique().tolist()\n",
    "item_dict = dict(zip(i_ids, [i for i in range(len(i_ids))]))\n",
    "df['item_id'] = df['item_id'].map(item_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZ3rlC7jO6WJ"
   },
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwS00lvHO-ca",
    "outputId": "f9f3a031-b4e7-439e-c3e3-c165b2286d19"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-fb140fbf3b12>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['user_id'] = train_df['user_id'].map(user_dict)\n",
      "<ipython-input-4-fb140fbf3b12>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  remain_df['user_id'] = remain_df['user_id'].map(user_dict)\n"
     ]
    }
   ],
   "source": [
    "# The number of training users and active users\n",
    "n_training_users = 300\n",
    "n_active_users = n_most_active_users - n_training_users\n",
    "\n",
    "# The number of GIVEN ratings for active users\n",
    "GIVEN = 20\n",
    "\n",
    "# Randomly select users from the most active users as training set\n",
    "random_uids = np.random.choice(df.user_id.unique(), n_training_users, replace=False)\n",
    "train_df = df[df['user_id'].isin(random_uids)]\n",
    "# Map new internal ID for all users in the training set\n",
    "u_ids = train_df['user_id'].unique().tolist()\n",
    "user_dict = dict(zip(u_ids, [i for i in range(len(u_ids))]))\n",
    "train_df['user_id'] = train_df['user_id'].map(user_dict)\n",
    "\n",
    "# The rest of users are active users for testing\n",
    "remain_df = df[~df['user_id'].isin(random_uids)]\n",
    "# Map new internal ID for all active users\n",
    "u_ids = remain_df['user_id'].unique().tolist()\n",
    "user_dict = dict(zip(u_ids, [i for i in range(len(u_ids))]))\n",
    "remain_df['user_id'] = remain_df['user_id'].map(user_dict)\n",
    "\n",
    "# Randomly select GIVEN ratings for active users\n",
    "active_df = remain_df.groupby('user_id').sample(n=GIVEN, random_state=1024)\n",
    "\n",
    "test_df = remain_df[~remain_df.index.isin(active_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-ke62G3jiYb",
    "outputId": "1c135984-edb4-4f2b-fc73-9225d86a0c38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        0.0  0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  4.0  ...  0.0  0.0  0.0   \n",
       " 1        4.0  0.0  5.0  0.0  0.0  3.0  4.0  2.0  0.0  2.0  ...  0.0  2.0  0.0   \n",
       " 2        0.0  4.0  0.0  0.0  0.0  0.0  3.0  0.0  0.0  4.0  ...  0.0  0.0  3.0   \n",
       " 3        0.0  0.0  0.0  0.0  0.0  5.0  4.0  4.0  0.0  5.0  ...  3.0  0.0  0.0   \n",
       " 4        0.0  0.0  0.0  3.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  4.0  3.0  0.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 295      4.0  0.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 296      0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 297      0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  3.0  4.0  0.0   \n",
       " 298      0.0  0.0  0.0  3.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  5.0   \n",
       " 299      0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  3.0  0.0  ...  4.0  0.0  0.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 1        0.0  0.0  0.0  0.0  4.0  0.0  0.0  \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 3        0.0  5.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 4        3.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 295      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 296      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 297      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 298      0.0  0.0  3.0  0.0  0.0  0.0  0.0  \n",
       " 299      5.0  0.0  0.0  3.0  0.0  0.0  0.0  \n",
       " \n",
       " [300 rows x 500 columns],\n",
       " item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 1        0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 195      0.0  0.0  0.0  0.0  0.0  0.0  5.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 197      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  ...  0.0  0.0  0.0   \n",
       " 198      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 199      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 195      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 197      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 198      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 199      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " \n",
       " [200 rows x 500 columns],\n",
       " item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 1        0.0  2.0  0.0  4.0  0.0  4.0  0.0  0.0  0.0  2.0  ...  0.0  4.0  4.0   \n",
       " 2        0.0  0.0  4.0  4.0  4.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 3        4.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 4        4.0  0.0  5.0  0.0  1.0  0.0  3.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 195      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  3.0  0.0  0.0   \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 197      0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 198      0.0  4.0  0.0  5.0  0.0  4.0  0.0  4.0  0.0  4.0  ...  0.0  0.0  0.0   \n",
       " 199      0.0  0.0  5.0  0.0  0.0  0.0  4.0  0.0  0.0  4.0  ...  0.0  0.0  0.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        0.0  0.0  0.0  4.0  0.0  3.0  0.0  \n",
       " 1        0.0  3.0  3.0  0.0  0.0  0.0  0.0  \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 4        4.0  1.0  0.0  0.0  0.0  0.0  2.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 195      5.0  0.0  0.0  3.0  5.0  4.0  0.0  \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 197      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 198      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 199      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " \n",
       " [200 rows x 500 columns])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the format of datasets to matrices\n",
    "df_zeros = pd.DataFrame({'user_id': np.tile(np.arange(0, n_training_users), n_most_active_items), 'item_id': np.repeat(np.arange(0, n_most_active_items), n_training_users), 'rating': 0})\n",
    "train_ds = df_zeros.merge(train_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "\n",
    "df_zeros = pd.DataFrame({'user_id': np.tile(np.arange(0, n_active_users), n_most_active_items), 'item_id': np.repeat(np.arange(0, n_most_active_items), n_active_users), 'rating': 0})\n",
    "active_ds = df_zeros.merge(active_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "test_ds = df_zeros.merge(test_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "\n",
    "train_ds, active_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yElYv2TDKKGu"
   },
   "outputs": [],
   "source": [
    "# Predicting All Missing Data in training set\n",
    "imputed_train_ds = train_ds.values.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iy4FurbHD4dt"
   },
   "source": [
    "# Your implementation to predict the missing values\n",
    "(Put all your implementation for your algorithm in the following cell only to handle the missing values; )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zYh1bVd0ncz3"
   },
   "outputs": [],
   "source": [
    "## Put all your implementation for your solutioin in this cell only to predict the missing values; \n",
    "## NOTE 1: DO NOT change anything in the rest of the cells in this framework, \n",
    "## otherwise the changes might cause errors and make your implementation invalid.\n",
    "\n",
    "## Note 2: \n",
    "## The user-item rating matrix is imputed_train_ds, \n",
    "## and the missing values are those 0s in imputed_train_ds. \n",
    "## You are required to predict them by using the solution in the given report. \n",
    "\n",
    "## The following parameters are required in the given report, \n",
    "## which is named \"Effective Missing Data Prediction for Collaborative Filtering\", \n",
    "## and you will need to use them. But, please do not change their values. \n",
    "LAMBDA = 0.7    # λ\n",
    "GAMMA = 10      # γ\n",
    "DELTA = 10      # δ\n",
    "ITA = 0.7       # η\n",
    "THETA = 0.7     # θ\n",
    "EPSILON = 1e-9\n",
    "\n",
    "train_user_pearson_corr = np.zeros((imputed_train_ds.shape[0], imputed_train_ds.shape[0]))\n",
    "\n",
    "# compute Pearson Correlation Coefficient of all pairs of users in the training set\n",
    "# loop through the rows of every pair of users\n",
    "for i, user_i in enumerate(imputed_train_ds):\n",
    "    for j, user_j in enumerate(imputed_train_ds):\n",
    "\n",
    "        # ratings given by two users respectively\n",
    "        mask_i = user_i > 0\n",
    "        mask_j = user_j > 0\n",
    "\n",
    "        # indices of items co-rated by both users\n",
    "        corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "        \n",
    "        # skip the current loop if there is no co-rated items\n",
    "        if len(corrated_index) == 0:\n",
    "            continue\n",
    "\n",
    "        # average rating given by two users\n",
    "        mean_user_i = np.sum(user_i) / (np.sum(np.clip(user_i, 0, 1)) + EPSILON)\n",
    "        mean_user_j = np.sum(user_j) / (np.sum(np.clip(user_j, 0, 1)) + EPSILON)\n",
    "\n",
    "        # normalise ratings\n",
    "        norm_i = user_i[corrated_index] - mean_user_i\n",
    "        norm_j = user_j[corrated_index] - mean_user_j\n",
    "\n",
    "        # compute pearson corr coeff\n",
    "        r_ui_sub_r_i_sq = np.square(norm_i)\n",
    "        r_uj_sub_r_j_sq = np.square(norm_j)\n",
    "\n",
    "        r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_r_i_sq))\n",
    "        r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_r_j_sq))\n",
    "\n",
    "        sim = np.sum(norm_i * norm_j) / (r_ui_sum_sqrt * r_uj_sum_sqrt + EPSILON)\n",
    "\n",
    "        # significance weighting\n",
    "        weighted_sim = (min(len(corrated_index), GAMMA) / GAMMA) * sim\n",
    "\n",
    "        train_user_pearson_corr[i][j] = weighted_sim\n",
    "\n",
    "train_item_pearson_corr = np.zeros((imputed_train_ds.shape[1], imputed_train_ds.shape[1]))\n",
    "\n",
    "# compute Pearson Correlation Coefficient of all pairs of items in the training set\n",
    "# transpose the user-item matrix into item-user matrix\n",
    "# loop through the rows of every pair of items\n",
    "for i, item_i in enumerate(imputed_train_ds.T):\n",
    "    for j, item_j in enumerate(imputed_train_ds.T):\n",
    "\n",
    "        # ratings received by two items respectively\n",
    "        mask_i = item_i > 0\n",
    "        mask_j = item_j > 0\n",
    "\n",
    "        # indices of users that rated both items\n",
    "        corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "        \n",
    "        # skip the current loop if there is no co-rated users\n",
    "        if len(corrated_index) == 0:\n",
    "            continue\n",
    "\n",
    "        # average rating received by two items\n",
    "        mean_item_i = np.sum(item_i) / (np.sum(np.clip(item_i, 0, 1)) + EPSILON)\n",
    "        mean_item_j = np.sum(item_j) / (np.sum(np.clip(item_j, 0, 1)) + EPSILON)\n",
    "\n",
    "        # normalise ratings\n",
    "        norm_i = item_i[corrated_index] - mean_item_i\n",
    "        norm_j = item_j[corrated_index] - mean_item_j\n",
    "\n",
    "        # compute pearson corr coeff\n",
    "        r_ui_sub_ri_sq = np.square(norm_i)\n",
    "        r_uj_sub_rj_sq = np.square(norm_j)\n",
    "\n",
    "        r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_ri_sq))\n",
    "        r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_rj_sq))\n",
    "\n",
    "        sim = np.sum(norm_i * norm_j) / (r_ui_sum_sqrt * r_uj_sum_sqrt + EPSILON)\n",
    "\n",
    "        # significance weighting\n",
    "        weighted_sim = (min(len(corrated_index), DELTA) / DELTA) * sim\n",
    "\n",
    "        train_item_pearson_corr[i][j] = weighted_sim\n",
    "        \n",
    "# predict missing values\n",
    "for (i, j), rating in np.ndenumerate(imputed_train_ds):\n",
    "    if rating == 0:\n",
    "        # user-based prediction\n",
    "        # find the user neighbours that pass the threshold, exclude the current user i itself\n",
    "        sim_user_ids = np.argsort(train_user_pearson_corr[i])\n",
    "        sim_user_ids = sim_user_ids[0:len(sim_user_ids) - 1]\n",
    "        sim_user_ids = sim_user_ids[train_user_pearson_corr[i][sim_user_ids] > ITA]\n",
    "        \n",
    "        # the similarity values of user neighbours\n",
    "        sim_val = train_user_pearson_corr[i][sim_user_ids]\n",
    "        \n",
    "        # the average rating given by current user i\n",
    "        user_mean = np.sum(train_ds.values[i]) / (np.sum(np.clip(train_ds.values[i], 0, 1)) + EPSILON)\n",
    "        \n",
    "        # the average rating given by each user neighbour\n",
    "        sim_users = train_ds.values[sim_user_ids]\n",
    "        sim_user_mean = np.sum(sim_users, axis=1) / (np.sum(np.clip(sim_users, 0, 1), axis=1) + EPSILON)\n",
    "        \n",
    "        # select the user neighbours who rated item j\n",
    "        mask_rated_j = sim_users[:, j] > 0\n",
    "        \n",
    "        # for each user neighbour who rated item j\n",
    "        # similarity of this neighbour * (this neighbour's rating on item j - this neighbour's average rating)\n",
    "        sim_r_sum_mean = sim_val[mask_rated_j] * (sim_users[mask_rated_j, j] - sim_user_mean[mask_rated_j])\n",
    "        \n",
    "        # compute user-based prediction\n",
    "        user_pred = user_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val[mask_rated_j]) + EPSILON)\n",
    "        \n",
    "        # item-based prediction\n",
    "        # find the item neighbours that pass the threshold, exclude the current item j itself\n",
    "        sim_item_ids = np.argsort(train_item_pearson_corr[j])\n",
    "        sim_item_ids = sim_item_ids[0:len(sim_item_ids) - 1]\n",
    "        sim_item_ids = sim_item_ids[train_item_pearson_corr[j][sim_item_ids] > THETA]\n",
    "        \n",
    "        # the similarity values of item neighbours\n",
    "        sim_item_val = train_item_pearson_corr[j][sim_item_ids]\n",
    "        \n",
    "        # the average rating received by current item j\n",
    "        item_mean = np.sum(train_ds.T.values[j]) / (np.sum(np.clip(train_ds.T.values[j], 0, 1)) + EPSILON)\n",
    "        \n",
    "        # the average rating received by each item neighbour\n",
    "        sim_items = train_ds.T.values[sim_item_ids]\n",
    "        sim_item_mean = np.sum(sim_items, axis=1) / (np.sum(np.clip(sim_items, 0, 1), axis=1) + EPSILON)\n",
    "        \n",
    "        # select the item neighbours which are rated by user i\n",
    "        mask_ratedby_i = sim_items[:, i] > 0\n",
    "        \n",
    "        # for each item neighbour which is rated by user i\n",
    "        # similarity of this neighbour * (this neighbour's rating from user i - this neighbour's average rating)\n",
    "        sim_item_r_sum_mean = sim_item_val[mask_ratedby_i] * (sim_items[mask_ratedby_i, i] - sim_item_mean[mask_ratedby_i])\n",
    "        \n",
    "        # compute item-based prediction\n",
    "        item_pred = item_mean + np.sum(sim_item_r_sum_mean) / (np.sum(sim_item_val[mask_ratedby_i]) + EPSILON)\n",
    "        \n",
    "        # compute final prediction\n",
    "        if len(sim_user_ids) > 0 and len(sim_item_ids) > 0:\n",
    "            rating_pred = LAMBDA * user_pred + (1 - LAMBDA) * item_pred\n",
    "        elif len(sim_user_ids) > 0 and len(sim_item_ids) == 0:\n",
    "            rating_pred = user_pred\n",
    "        elif len(sim_user_ids) == 0 and len(sim_item_ids) > 0:\n",
    "            rating_pred = item_pred\n",
    "        else:\n",
    "            rating_pred = 0\n",
    "        \n",
    "        # enforce the valid range of ratings\n",
    "        rating_pred = np.clip(rating_pred, 0, 5)\n",
    "        \n",
    "        imputed_train_ds[i][j] = rating_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbOfVWTV_Aij"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Txs8YjwTzuSP"
   },
   "source": [
    "### Compute Pearson Correlation Coefficient of All Pairs of Items between active set and imputed training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "KoOgX_axKKGw",
    "outputId": "37a7adbd-e0d6-4375-e28c-3940977896f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.156250</td>\n",
       "      <td>3.441860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.845528</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.367816</td>\n",
       "      <td>3.811594</td>\n",
       "      <td>3.280202</td>\n",
       "      <td>4.029439</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.857447</td>\n",
       "      <td>2.342491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.892857</td>\n",
       "      <td>2.893617</td>\n",
       "      <td>2.351351</td>\n",
       "      <td>1.604487</td>\n",
       "      <td>4.607317</td>\n",
       "      <td>2.677419</td>\n",
       "      <td>4.322316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.166656</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.845528</td>\n",
       "      <td>0.653680</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.029439</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.032447</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.185540</td>\n",
       "      <td>2.893617</td>\n",
       "      <td>2.351351</td>\n",
       "      <td>2.297297</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.677419</td>\n",
       "      <td>1.817426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.556735</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.241596</td>\n",
       "      <td>3.361906</td>\n",
       "      <td>3.897537</td>\n",
       "      <td>3.573816</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.547532</td>\n",
       "      <td>3.136154</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.102812</td>\n",
       "      <td>2.910995</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.810390</td>\n",
       "      <td>2.976333</td>\n",
       "      <td>2.913653</td>\n",
       "      <td>2.999050</td>\n",
       "      <td>2.954496</td>\n",
       "      <td>3.265319</td>\n",
       "      <td>3.168247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.156250</td>\n",
       "      <td>3.794716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.845528</td>\n",
       "      <td>4.539393</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.745197</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.966985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.892857</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.351351</td>\n",
       "      <td>0.604487</td>\n",
       "      <td>3.871285</td>\n",
       "      <td>2.677419</td>\n",
       "      <td>4.582353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.938321</td>\n",
       "      <td>3.436283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.362238</td>\n",
       "      <td>4.117816</td>\n",
       "      <td>4.006083</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.819823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.560284</td>\n",
       "      <td>2.351351</td>\n",
       "      <td>2.124588</td>\n",
       "      <td>3.739458</td>\n",
       "      <td>2.677419</td>\n",
       "      <td>2.582353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.369932</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.635477</td>\n",
       "      <td>3.676492</td>\n",
       "      <td>3.492163</td>\n",
       "      <td>3.534387</td>\n",
       "      <td>3.465879</td>\n",
       "      <td>3.409725</td>\n",
       "      <td>3.545455</td>\n",
       "      <td>...</td>\n",
       "      <td>2.947877</td>\n",
       "      <td>3.186920</td>\n",
       "      <td>3.545455</td>\n",
       "      <td>3.649675</td>\n",
       "      <td>3.349903</td>\n",
       "      <td>2.889075</td>\n",
       "      <td>3.263164</td>\n",
       "      <td>3.492484</td>\n",
       "      <td>3.285044</td>\n",
       "      <td>3.398961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>4.276726</td>\n",
       "      <td>4.062409</td>\n",
       "      <td>4.328358</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.356111</td>\n",
       "      <td>4.040196</td>\n",
       "      <td>4.173329</td>\n",
       "      <td>4.170834</td>\n",
       "      <td>4.238683</td>\n",
       "      <td>4.328358</td>\n",
       "      <td>...</td>\n",
       "      <td>3.917085</td>\n",
       "      <td>4.334953</td>\n",
       "      <td>4.328358</td>\n",
       "      <td>4.327253</td>\n",
       "      <td>3.585436</td>\n",
       "      <td>3.735256</td>\n",
       "      <td>3.719040</td>\n",
       "      <td>4.142046</td>\n",
       "      <td>3.833077</td>\n",
       "      <td>3.792057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>4.156250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.845528</td>\n",
       "      <td>2.778642</td>\n",
       "      <td>3.367816</td>\n",
       "      <td>3.042363</td>\n",
       "      <td>3.803279</td>\n",
       "      <td>3.452508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.892857</td>\n",
       "      <td>3.560284</td>\n",
       "      <td>2.351351</td>\n",
       "      <td>2.297297</td>\n",
       "      <td>3.707317</td>\n",
       "      <td>2.677419</td>\n",
       "      <td>3.817426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>4.204328</td>\n",
       "      <td>2.932524</td>\n",
       "      <td>2.944444</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.118254</td>\n",
       "      <td>2.996456</td>\n",
       "      <td>3.204589</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.989018</td>\n",
       "      <td>3.224932</td>\n",
       "      <td>...</td>\n",
       "      <td>1.268280</td>\n",
       "      <td>2.850397</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.228968</td>\n",
       "      <td>2.929196</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.750300</td>\n",
       "      <td>3.457090</td>\n",
       "      <td>2.864337</td>\n",
       "      <td>2.835817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>3.816024</td>\n",
       "      <td>3.914473</td>\n",
       "      <td>4.738840</td>\n",
       "      <td>3.722807</td>\n",
       "      <td>3.626292</td>\n",
       "      <td>4.104494</td>\n",
       "      <td>3.712627</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.670213</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.775887</td>\n",
       "      <td>3.670213</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.437234</td>\n",
       "      <td>3.274554</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.811446</td>\n",
       "      <td>3.372375</td>\n",
       "      <td>3.643855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    4.156250  3.441860  0.000000  3.845528  5.000000  3.367816  3.811594   \n",
       "1    4.000000  4.166656  5.000000  3.845528  0.653680  3.000000  4.000000   \n",
       "2    3.556735  4.000000  3.241596  3.361906  3.897537  3.573816  3.000000   \n",
       "3    4.156250  3.794716  0.000000  3.845528  4.539393  5.000000  4.000000   \n",
       "4    3.938321  3.436283  0.000000  3.000000  3.362238  4.117816  4.006083   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "295  4.000000  3.369932  3.000000  3.635477  3.676492  3.492163  3.534387   \n",
       "296  4.276726  4.062409  4.328358  5.000000  4.356111  4.040196  4.173329   \n",
       "297  4.156250  1.000000  0.000000  3.845528  2.778642  3.367816  3.042363   \n",
       "298  4.204328  2.932524  2.944444  3.000000  3.118254  2.996456  3.204589   \n",
       "299  3.816024  3.914473  4.738840  3.722807  3.626292  4.104494  3.712627   \n",
       "\n",
       "          7         8         9    ...       490       491       492  \\\n",
       "0    3.280202  4.029439  4.000000  ...  3.857447  2.342491  0.000000   \n",
       "1    2.000000  2.029439  2.000000  ...  2.032447  2.000000  0.000000   \n",
       "2    3.547532  3.136154  4.000000  ...  3.102812  2.910995  3.000000   \n",
       "3    4.000000  2.745197  5.000000  ...  3.000000  2.966985  0.000000   \n",
       "4    4.000000  2.819823  0.000000  ...  4.000000  3.000000  0.000000   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "295  3.465879  3.409725  3.545455  ...  2.947877  3.186920  3.545455   \n",
       "296  4.170834  4.238683  4.328358  ...  3.917085  4.334953  4.328358   \n",
       "297  3.803279  3.452508  0.000000  ...  3.000000  4.000000  0.000000   \n",
       "298  4.000000  2.989018  3.224932  ...  1.268280  2.850397  5.000000   \n",
       "299  3.000000  3.000000  3.670213  ...  4.000000  3.775887  3.670213   \n",
       "\n",
       "          493       494       495       496       497       498       499  \n",
       "0    3.892857  2.893617  2.351351  1.604487  4.607317  2.677419  4.322316  \n",
       "1    4.185540  2.893617  2.351351  2.297297  4.000000  2.677419  1.817426  \n",
       "2    2.810390  2.976333  2.913653  2.999050  2.954496  3.265319  3.168247  \n",
       "3    3.892857  5.000000  2.351351  0.604487  3.871285  2.677419  4.582353  \n",
       "4    3.000000  1.560284  2.351351  2.124588  3.739458  2.677419  2.582353  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "295  3.649675  3.349903  2.889075  3.263164  3.492484  3.285044  3.398961  \n",
       "296  4.327253  3.585436  3.735256  3.719040  4.142046  3.833077  3.792057  \n",
       "297  3.892857  3.560284  2.351351  2.297297  3.707317  2.677419  3.817426  \n",
       "298  3.228968  2.929196  3.000000  2.750300  3.457090  2.864337  2.835817  \n",
       "299  5.000000  3.437234  3.274554  3.000000  3.811446  3.372375  3.643855  \n",
       "\n",
       "[300 rows x 500 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_train_ds = pd.DataFrame(imputed_train_ds)\n",
    "imputed_train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eq0uq1aHzu11",
    "outputId": "f6214a46-d63e-4fdc-e7dd-ccaed23b237d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13490673,  0.16490938,  0.30615924, ..., -0.0122867 ,\n",
       "         0.36650816, -0.19250559],\n",
       "       [ 0.19622043,  0.37890189, -0.04285867, ...,  0.47183079,\n",
       "         0.39774746,  0.24787326],\n",
       "       [ 0.21572646, -0.08744522, -0.0824993 , ...,  0.35087124,\n",
       "        -0.18021959,  0.12692653],\n",
       "       ...,\n",
       "       [ 0.43885845,  0.18940392,  0.15292347, ...,  0.30316112,\n",
       "        -0.32521344,  0.4774363 ],\n",
       "       [ 0.42289589,  0.42497621,  0.23411608, ...,  0.18484718,\n",
       "         0.30470159,  0.0765803 ],\n",
       "       [ 0.38799218,  0.04256656,  0.07215277, ..., -0.25869053,\n",
       "        -0.064573  ,  0.2929065 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_user_pearson_corr = np.zeros((active_ds.shape[0], train_ds.shape[0]))\n",
    "\n",
    "# Compute Pearson Correlation Coefficient of All Pairs of Users between active set and imputed training set\n",
    "for i, user_i_vec in enumerate(active_ds.values):\n",
    "    for j, user_j_vec in enumerate(imputed_train_ds.values):\n",
    "        \n",
    "        # ratings corated by the current pair of users\n",
    "        mask_i = user_i_vec > 0\n",
    "        mask_j = user_j_vec > 0\n",
    "\n",
    "        # corrated item index, skip if there are no corrated ratings\n",
    "        corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "        if len(corrated_index) == 0:\n",
    "            continue\n",
    "\n",
    "        # average value of user_i_vec and user_j_vec\n",
    "        mean_user_i = np.sum(user_i_vec) / (np.sum(np.clip(user_i_vec, 0, 1)) + EPSILON)\n",
    "        mean_user_j = np.sum(user_j_vec) / (np.sum(np.clip(user_j_vec, 0, 1)) + EPSILON)\n",
    "\n",
    "        # compute pearson corr\n",
    "        user_i_sub_mean = user_i_vec[corrated_index] - mean_user_i\n",
    "        user_j_sub_mean = user_j_vec[corrated_index] - mean_user_j\n",
    "\n",
    "        r_ui_sub_r_i_sq = np.square(user_i_sub_mean)\n",
    "        r_uj_sub_r_j_sq = np.square(user_j_sub_mean)\n",
    "\n",
    "        r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_r_i_sq))\n",
    "        r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_r_j_sq))\n",
    "\n",
    "        sim = np.sum(user_i_sub_mean * user_j_sub_mean) / (r_ui_sum_sqrt * r_uj_sum_sqrt + EPSILON)\n",
    "\n",
    "        # significance weighting\n",
    "        weighted_sim = (min(len(corrated_index), GAMMA) / GAMMA) * sim\n",
    "\n",
    "        active_user_pearson_corr[i][j] = weighted_sim\n",
    "\n",
    "active_user_pearson_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewTnN9kNb8Ys"
   },
   "source": [
    "## Predict Ratings of Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4ERndYXb8Ys",
    "outputId": "12607670-af61-403a-e4ce-f5e874bf8386"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 2.77067163,\n",
       "        0.        ],\n",
       "       [0.        , 3.3410317 , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 4.65854001, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 3.5398246 , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 4.46200736, ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 10\n",
    "\n",
    "test_ds_pred = np.zeros_like(test_ds.values)\n",
    "\n",
    "for (i, j), rating in np.ndenumerate(test_ds.values):\n",
    "\n",
    "    if rating > 0:\n",
    "\n",
    "        sim_user_ids = np.argsort(active_user_pearson_corr[i])[-1:-(K + 1):-1]\n",
    "\n",
    "        #==================user-based==================#\n",
    "        # the coefficient values of similar users\n",
    "        sim_val = active_user_pearson_corr[i][sim_user_ids]\n",
    "\n",
    "        # the average value of the current user's ratings\n",
    "        sim_users = imputed_train_ds.values[sim_user_ids]\n",
    "        user_mean = np.sum(active_ds.values[i]) / (np.sum(np.clip(active_ds.values[i], 0, 1)) + EPSILON)\n",
    "        sim_user_mean = np.sum(sim_users, axis=1) / (np.sum(np.clip(sim_users, 0, 1), axis=1) + EPSILON)\n",
    "\n",
    "        # select the users who rated item j\n",
    "        mask_rated_j = sim_users[:, j] > 0\n",
    "        \n",
    "        # sim(u, v) * (r_vj - mean_v)\n",
    "        sim_r_sum_mean = sim_val[mask_rated_j] * (sim_users[mask_rated_j, j] - sim_user_mean[mask_rated_j])\n",
    "        \n",
    "        user_based_pred = user_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val[mask_rated_j]) + EPSILON)\n",
    "        user_based_pred = np.clip(user_based_pred, 0, 5)\n",
    "\n",
    "        test_ds_pred[i][j] = user_based_pred\n",
    "        \n",
    "test_ds_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUTn4kSFb8ZA"
   },
   "source": [
    "## Compute MAE and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7JCVmexyb8ZA",
    "outputId": "6f650170-e9a6-482a-b695-5fa474d964b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.7288451770359519, RMSE: 0.9353799951033979\n"
     ]
    }
   ],
   "source": [
    "# MAE\n",
    "MAE = np.sum(np.abs(test_ds_pred - test_ds.values)) / np.sum(np.clip(test_ds.values, 0, 1))\n",
    "\n",
    "# RMSE\n",
    "RMSE = np.sqrt(np.sum(np.square(test_ds_pred - test_ds.values)) / np.sum(np.clip(test_ds.values, 0, 1)))\n",
    "\n",
    "print(\"MAE: {}, RMSE: {}\" .format(MAE, RMSE))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment3_framework.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
